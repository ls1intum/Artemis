name: E2E Tests

on:
  workflow_run:
    # Must match the name of build.yml workflow.
    workflows: ["Build"]
    types: [completed]

concurrency:
  group: |
    ${{
      github.event.workflow_run.head_branch && format('e2e-{0}', github.event.workflow_run.head_branch)
      || format('e2e-{0}', github.event.workflow_run.head_sha)
    }}
  cancel-in-progress: true

env:
  # This is the context of the status. It will be displayed in the GitHub Actions UI.
  STATUS_CONTEXT: "End-to-End (E2E) Tests"
  # This is the URL to make a request to the GitHub API to update the status of the workflow run.
  STATUSES_REQUEST_URL: "https://api.github.com/repos/${{ github.repository }}/statuses/${{ github.event.workflow_run.head_sha }}"
  # This is the URL to the workflow run in the GitHub Actions UI.
  TARGET_URL: "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"

jobs:
  # Job to determine which tests are relevant based on changed files (only for PRs)
  determine-tests:
    name: Determine Relevant Tests
    if: github.event.workflow_run.conclusion == 'success' && github.event.workflow_run.event == 'pull_request'
    runs-on: ubuntu-latest
    outputs:
      run_all_tests: ${{ steps.determine.outputs.RUN_ALL_TESTS }}
      relevant_tests: ${{ steps.determine.outputs.RELEVANT_TESTS }}
      remaining_tests: ${{ steps.determine.outputs.REMAINING_TESTS }}
      ignore_tests: ${{ steps.determine.outputs.IGNORE_TESTS }}
      relevant_count: ${{ steps.determine.outputs.RELEVANT_COUNT }}
      remaining_count: ${{ steps.determine.outputs.REMAINING_COUNT }}
    steps:
      - name: Git Checkout
        uses: actions/checkout@v6
        with:
          ref: ${{ github.event.workflow_run.head_branch }}
          fetch-depth: 0

      - name: Fetch base branch
        run: |
          # Try to get base branch from PR info, fallback to develop
          BASE_REF="develop"
          if [ -n "${{ github.event.workflow_run.pull_requests[0].base.ref }}" ]; then
            BASE_REF="${{ github.event.workflow_run.pull_requests[0].base.ref }}"
          fi
          echo "Fetching base branch: $BASE_REF"
          git fetch origin "$BASE_REF":base_branch || git fetch origin develop:base_branch

      - name: Determine relevant tests
        id: determine
        run: |
          chmod +x .ci/E2E-tests/determine-relevant-tests.sh
          .ci/E2E-tests/determine-relevant-tests.sh base_branch

  # Phase 1: Run relevant tests for PR changes
  run-e2e-relevant:
    name: "Phase 1: Relevant E2E Tests"
    needs: determine-tests
    if: |
      needs.determine-tests.result == 'success' &&
      needs.determine-tests.outputs.run_all_tests != 'true' &&
      needs.determine-tests.outputs.relevant_tests != ''
    runs-on: [self-hosted, e2e-test]
    environment: playwright-e2e-tests
    timeout-minutes: 60
    env:
      ARTEMIS_ADMIN_PASSWORD: ${{ secrets.ARTEMIS_ADMIN_PASSWORD }}
      ARTEMIS_ADMIN_USERNAME: ${{ secrets.ARTEMIS_ADMIN_USERNAME }}
      PLAYWRIGHT_CREATE_USERS: ${{ vars.PLAYWRIGHT_CREATE_USERS }}
      PLAYWRIGHT_PASSWORD_TEMPLATE: ${{ vars.PLAYWRIGHT_PASSWORD_TEMPLATE }}
      PLAYWRIGHT_USERNAME_TEMPLATE: ${{ vars.PLAYWRIGHT_USERNAME_TEMPLATE }}
      SLOW_TEST_TIMEOUT_SECONDS: ${{ vars.SLOW_TEST_TIMEOUT_SECONDS }}
      TEST_RETRIES: ${{ vars.TEST_RETRIES }}
      TEST_TIMEOUT_SECONDS: ${{ vars.TEST_TIMEOUT_SECONDS }}
      TEST_WORKER_PROCESSES: ${{ vars.TEST_WORKER_PROCESSES }}
    outputs:
      phase1_status: ${{ job.status }}
    steps:
      # workflow_run events do not create check runs, so we set a status manually
      - name: Create pending status
        run: |
          curl -X POST \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "${{ env.STATUSES_REQUEST_URL }}" \
            -d '{"state":"pending","context":"${{ env.STATUS_CONTEXT }}","description":"Phase 1: Running relevant tests (${{ needs.determine-tests.outputs.relevant_count }} test paths)...","target_url":"${{ env.TARGET_URL }}"}'

      - name: Save triggering workflow info
        run: |
          echo "TRIGGERING_WORKFLOW_RUN_ID=${{ github.event.workflow_run.id }}" > workflow-context.txt
          echo "TRIGGERING_WORKFLOW_HEAD_BRANCH=${{ github.event.workflow_run.head_branch }}" >> workflow-context.txt
          echo "TRIGGERING_WORKFLOW_HEAD_SHA=${{ github.event.workflow_run.head_sha }}" >> workflow-context.txt
          cat workflow-context.txt

      - name: Upload workflow context
        uses: actions/upload-artifact@v5
        with:
          name: workflow-context-phase1
          path: workflow-context.txt

      - name: Add link to triggering workflow
        run: |
          echo "::notice title=Triggered by workflow run::This E2E test was triggered by workflow run #${{ github.event.workflow_run.id }} - View it at https://github.com/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }}"
          echo "::notice title=Test Selection::Running Phase 1 with relevant tests: ${{ needs.determine-tests.outputs.relevant_tests }}"

      - name: Git Checkout
        uses: actions/checkout@v6
        with:
          ref: ${{ github.event.workflow_run.head_branch }}

      - name: Download Docker tag
        uses: actions/download-artifact@v6
        with:
          name: docker-tag
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}

      - name: Set Docker Tag Environment Variable
        run: |
          if [ -f "docker-tag.txt" ]; then
            ARTEMIS_DOCKER_TAG=$(cat docker-tag.txt)
            echo "ARTEMIS_DOCKER_TAG=${ARTEMIS_DOCKER_TAG}" >> $GITHUB_ENV
            echo "Using Docker tag: ${ARTEMIS_DOCKER_TAG}"
          else
            echo "::error::No docker-tag.txt found in the previous build workflow! Artifact is needed to run E2E tests."
            exit 1
          fi

      - name: Make scripts executable
        run: |
          chmod +x .ci/E2E-tests/cleanup.sh
          chmod +x .ci/E2E-tests/execute.sh

      - name: Run cleanup script (before E2E)
        run: .ci/E2E-tests/cleanup.sh

      - name: Run E2E Playwright tests (Phase 1 - Relevant Tests)
        run: .ci/E2E-tests/execute.sh mysql-localci playwright "${{ needs.determine-tests.outputs.relevant_tests }}"
        env:
          FAST_TEST_TIMEOUT_SECONDS: 60

      - name: Upload JUnit Test Results (Phase 1)
        if: success() || failure()
        uses: actions/upload-artifact@v5
        with:
          name: JUnit Test Results Phase 1
          if-no-files-found: warn
          path: src/test/playwright/test-reports/*.xml

      - name: Upload Client Test Coverage Report (Phase 1)
        if: success() || failure()
        uses: actions/upload-artifact@v5
        with:
          name: E2E Client Coverage Report Phase 1
          path: src/test/playwright/test-reports/client-coverage

      - name: Run cleanup script (after E2E)
        run: .ci/E2E-tests/cleanup.sh

  # Phase 2: Run remaining tests only if Phase 1 succeeds
  run-e2e-remaining:
    name: "Phase 2: Remaining E2E Tests"
    needs: [determine-tests, run-e2e-relevant]
    if: |
      always() &&
      needs.determine-tests.result == 'success' &&
      needs.determine-tests.outputs.run_all_tests != 'true' &&
      needs.determine-tests.outputs.remaining_tests != '' &&
      (needs.run-e2e-relevant.result == 'success' || needs.run-e2e-relevant.result == 'skipped')
    runs-on: [self-hosted, e2e-test]
    environment: playwright-e2e-tests
    timeout-minutes: 60
    env:
      ARTEMIS_ADMIN_PASSWORD: ${{ secrets.ARTEMIS_ADMIN_PASSWORD }}
      ARTEMIS_ADMIN_USERNAME: ${{ secrets.ARTEMIS_ADMIN_USERNAME }}
      PLAYWRIGHT_CREATE_USERS: ${{ vars.PLAYWRIGHT_CREATE_USERS }}
      PLAYWRIGHT_PASSWORD_TEMPLATE: ${{ vars.PLAYWRIGHT_PASSWORD_TEMPLATE }}
      PLAYWRIGHT_USERNAME_TEMPLATE: ${{ vars.PLAYWRIGHT_USERNAME_TEMPLATE }}
      SLOW_TEST_TIMEOUT_SECONDS: ${{ vars.SLOW_TEST_TIMEOUT_SECONDS }}
      TEST_RETRIES: ${{ vars.TEST_RETRIES }}
      TEST_TIMEOUT_SECONDS: ${{ vars.TEST_TIMEOUT_SECONDS }}
      TEST_WORKER_PROCESSES: ${{ vars.TEST_WORKER_PROCESSES }}
    steps:
      - name: Update status to Phase 2
        run: |
          curl -X POST \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "${{ env.STATUSES_REQUEST_URL }}" \
            -d '{"state":"pending","context":"${{ env.STATUS_CONTEXT }}","description":"Phase 2: Running remaining tests (${{ needs.determine-tests.outputs.remaining_count }} test paths)...","target_url":"${{ env.TARGET_URL }}"}'

      - name: Add notice for Phase 2
        run: |
          echo "::notice title=Test Selection::Running Phase 2 with remaining tests: ${{ needs.determine-tests.outputs.remaining_tests }}"

      - name: Git Checkout
        uses: actions/checkout@v6
        with:
          ref: ${{ github.event.workflow_run.head_branch }}

      - name: Download Docker tag
        uses: actions/download-artifact@v6
        with:
          name: docker-tag
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}

      - name: Set Docker Tag Environment Variable
        run: |
          if [ -f "docker-tag.txt" ]; then
            ARTEMIS_DOCKER_TAG=$(cat docker-tag.txt)
            echo "ARTEMIS_DOCKER_TAG=${ARTEMIS_DOCKER_TAG}" >> $GITHUB_ENV
            echo "Using Docker tag: ${ARTEMIS_DOCKER_TAG}"
          else
            echo "::error::No docker-tag.txt found in the previous build workflow! Artifact is needed to run E2E tests."
            exit 1
          fi

      - name: Make scripts executable
        run: |
          chmod +x .ci/E2E-tests/cleanup.sh
          chmod +x .ci/E2E-tests/execute.sh

      - name: Run cleanup script (before E2E)
        run: .ci/E2E-tests/cleanup.sh

      - name: Run E2E Playwright tests (Phase 2 - Remaining Tests)
        run: .ci/E2E-tests/execute.sh mysql-localci playwright "${{ needs.determine-tests.outputs.remaining_tests }}" "${{ needs.determine-tests.outputs.ignore_tests }}"
        env:
          FAST_TEST_TIMEOUT_SECONDS: 60

      - name: Upload JUnit Test Results (Phase 2)
        if: success() || failure()
        uses: actions/upload-artifact@v5
        with:
          name: JUnit Test Results Phase 2
          if-no-files-found: warn
          path: src/test/playwright/test-reports/*.xml

      - name: Upload Client Test Coverage Report (Phase 2)
        if: success() || failure()
        uses: actions/upload-artifact@v5
        with:
          name: E2E Client Coverage Report Phase 2
          path: src/test/playwright/test-reports/client-coverage

      - name: Run cleanup script (after E2E)
        run: .ci/E2E-tests/cleanup.sh

  # Run all tests for PR when run_all_tests is triggered, or when no specific tests detected
  run-e2e-all-pr:
    name: Run All E2E Tests (PR)
    needs: determine-tests
    if: |
      needs.determine-tests.result == 'success' &&
      (needs.determine-tests.outputs.run_all_tests == 'true' ||
       (needs.determine-tests.outputs.relevant_tests == '' && needs.determine-tests.outputs.remaining_tests == ''))
    runs-on: [self-hosted, e2e-test]
    environment: playwright-e2e-tests
    timeout-minutes: 90
    env:
      ARTEMIS_ADMIN_PASSWORD: ${{ secrets.ARTEMIS_ADMIN_PASSWORD }}
      ARTEMIS_ADMIN_USERNAME: ${{ secrets.ARTEMIS_ADMIN_USERNAME }}
      PLAYWRIGHT_CREATE_USERS: ${{ vars.PLAYWRIGHT_CREATE_USERS }}
      PLAYWRIGHT_PASSWORD_TEMPLATE: ${{ vars.PLAYWRIGHT_PASSWORD_TEMPLATE }}
      PLAYWRIGHT_USERNAME_TEMPLATE: ${{ vars.PLAYWRIGHT_USERNAME_TEMPLATE }}
      SLOW_TEST_TIMEOUT_SECONDS: ${{ vars.SLOW_TEST_TIMEOUT_SECONDS }}
      TEST_RETRIES: ${{ vars.TEST_RETRIES }}
      TEST_TIMEOUT_SECONDS: ${{ vars.TEST_TIMEOUT_SECONDS }}
      TEST_WORKER_PROCESSES: ${{ vars.TEST_WORKER_PROCESSES }}
    steps:
      - name: Create pending status
        run: |
          curl -X POST \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "${{ env.STATUSES_REQUEST_URL }}" \
            -d '{"state":"pending","context":"${{ env.STATUS_CONTEXT }}","description":"E2E tests are running (all tests - infrastructure changes detected)...","target_url":"${{ env.TARGET_URL }}"}'

      - name: Save triggering workflow info
        run: |
          echo "TRIGGERING_WORKFLOW_RUN_ID=${{ github.event.workflow_run.id }}" > workflow-context.txt
          echo "TRIGGERING_WORKFLOW_HEAD_BRANCH=${{ github.event.workflow_run.head_branch }}" >> workflow-context.txt
          echo "TRIGGERING_WORKFLOW_HEAD_SHA=${{ github.event.workflow_run.head_sha }}" >> workflow-context.txt
          cat workflow-context.txt

      - name: Upload workflow context
        uses: actions/upload-artifact@v5
        with:
          name: workflow-context
          path: workflow-context.txt

      # Add a notice to help navigate back to the triggering build workflow
      - name: Add link to triggering workflow
        run: |
          echo "::notice title=Triggered by workflow run::This E2E test was triggered by workflow run #${{ github.event.workflow_run.id }} - View it at https://github.com/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }}"
          echo "::notice title=Test Selection::Running all tests (infrastructure/config changes detected)"

      - name: Git Checkout
        uses: actions/checkout@v6
        with:
          ref: ${{ github.event.workflow_run.head_branch }}

      - name: Download Docker tag
        uses: actions/download-artifact@v6
        with:
          name: docker-tag
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}

      - name: Set Docker Tag Environment Variable
        run: |
          if [ -f "docker-tag.txt" ]; then
            ARTEMIS_DOCKER_TAG=$(cat docker-tag.txt)
            echo "ARTEMIS_DOCKER_TAG=${ARTEMIS_DOCKER_TAG}" >> $GITHUB_ENV
            echo "Using Docker tag: ${ARTEMIS_DOCKER_TAG}"
          else
            echo "::error::No docker-tag.txt found in the previous build workflow! Artifact is needed to run E2E tests."
            exit 1
          fi

      - name: Make scripts executable
        run: |
          chmod +x .ci/E2E-tests/cleanup.sh
          chmod +x .ci/E2E-tests/execute.sh

      - name: Run cleanup script (before E2E)
        run: .ci/E2E-tests/cleanup.sh

      - name: Run E2E Playwright tests (MySQL, Local)
        run: .ci/E2E-tests/execute.sh mysql-localci playwright
        env:
          FAST_TEST_TIMEOUT_SECONDS: 60

      - name: Upload JUnit Test Results
        if: success() || failure()
        uses: actions/upload-artifact@v5
        with:
          name: JUnit Test Results
          if-no-files-found: error
          path: src/test/playwright/test-reports/*.xml

      - name: Upload Client Test Coverage Report
        if: success() || failure()
        uses: actions/upload-artifact@v5
        with:
          name: E2E Client Coverage Report
          path: src/test/playwright/test-reports/client-coverage

      - name: Run cleanup script (after E2E)
        run: .ci/E2E-tests/cleanup.sh

  # Run all tests for non-PR events (push to develop, main, release branches)
  run-e2e-all-non-pr:
    name: Run All E2E Tests (Non-PR)
    if: github.event.workflow_run.conclusion == 'success' && github.event.workflow_run.event != 'pull_request'
    runs-on: [self-hosted, e2e-test]
    environment: playwright-e2e-tests
    timeout-minutes: 90
    env:
      ARTEMIS_ADMIN_PASSWORD: ${{ secrets.ARTEMIS_ADMIN_PASSWORD }}
      ARTEMIS_ADMIN_USERNAME: ${{ secrets.ARTEMIS_ADMIN_USERNAME }}
      PLAYWRIGHT_CREATE_USERS: ${{ vars.PLAYWRIGHT_CREATE_USERS }}
      PLAYWRIGHT_PASSWORD_TEMPLATE: ${{ vars.PLAYWRIGHT_PASSWORD_TEMPLATE }}
      PLAYWRIGHT_USERNAME_TEMPLATE: ${{ vars.PLAYWRIGHT_USERNAME_TEMPLATE }}
      SLOW_TEST_TIMEOUT_SECONDS: ${{ vars.SLOW_TEST_TIMEOUT_SECONDS }}
      TEST_RETRIES: ${{ vars.TEST_RETRIES }}
      TEST_TIMEOUT_SECONDS: ${{ vars.TEST_TIMEOUT_SECONDS }}
      TEST_WORKER_PROCESSES: ${{ vars.TEST_WORKER_PROCESSES }}
    steps:
      - name: Create pending status
        run: |
          curl -X POST \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "${{ env.STATUSES_REQUEST_URL }}" \
            -d '{"state":"pending","context":"${{ env.STATUS_CONTEXT }}","description":"E2E tests are running (all tests - multi-node)...","target_url":"${{ env.TARGET_URL }}"}'

      - name: Save triggering workflow info
        run: |
          echo "TRIGGERING_WORKFLOW_RUN_ID=${{ github.event.workflow_run.id }}" > workflow-context.txt
          echo "TRIGGERING_WORKFLOW_HEAD_BRANCH=${{ github.event.workflow_run.head_branch }}" >> workflow-context.txt
          echo "TRIGGERING_WORKFLOW_HEAD_SHA=${{ github.event.workflow_run.head_sha }}" >> workflow-context.txt
          cat workflow-context.txt

      - name: Upload workflow context
        uses: actions/upload-artifact@v5
        with:
          name: workflow-context
          path: workflow-context.txt

      - name: Add link to triggering workflow
        run: |
          echo "::notice title=Triggered by workflow run::This E2E test was triggered by workflow run #${{ github.event.workflow_run.id }} - View it at https://github.com/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }}"

      - name: Git Checkout
        uses: actions/checkout@v6
        with:
          ref: ${{ github.event.workflow_run.head_branch }}

      - name: Download Docker tag
        uses: actions/download-artifact@v6
        with:
          name: docker-tag
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}

      - name: Set Docker Tag Environment Variable
        run: |
          if [ -f "docker-tag.txt" ]; then
            ARTEMIS_DOCKER_TAG=$(cat docker-tag.txt)
            echo "ARTEMIS_DOCKER_TAG=${ARTEMIS_DOCKER_TAG}" >> $GITHUB_ENV
            echo "Using Docker tag: ${ARTEMIS_DOCKER_TAG}"
          else
            echo "::error::No docker-tag.txt found in the previous build workflow! Artifact is needed to run E2E tests."
            exit 1
          fi

      - name: Make scripts executable
        run: |
          chmod +x .ci/E2E-tests/cleanup.sh
          chmod +x .ci/E2E-tests/execute.sh

      - name: Run cleanup script (before E2E)
        run: .ci/E2E-tests/cleanup.sh

      - name: Run E2E Playwright tests (MySQL, Local, Multi-Node)
        run: .ci/E2E-tests/execute.sh multi-node playwright
        env:
          FAST_TEST_TIMEOUT_SECONDS: 75

      - name: Upload JUnit Test Results
        if: success() || failure()
        uses: actions/upload-artifact@v5
        with:
          name: JUnit Test Results
          if-no-files-found: error
          path: src/test/playwright/test-reports/*.xml

      - name: Upload Client Test Coverage Report
        if: success() || failure()
        uses: actions/upload-artifact@v5
        with:
          name: E2E Client Coverage Report
          path: src/test/playwright/test-reports/client-coverage

      - name: Run cleanup script (after E2E)
        run: .ci/E2E-tests/cleanup.sh

  # Aggregate results and report
  report-results:
    name: Report E2E Results
    needs: [determine-tests, run-e2e-relevant, run-e2e-remaining, run-e2e-all-pr, run-e2e-all-non-pr]
    if: always() && github.event.workflow_run.conclusion == 'success'
    runs-on: ubuntu-latest
    steps:
      - name: Download Phase 1 test results
        if: needs.run-e2e-relevant.result == 'success' || needs.run-e2e-relevant.result == 'failure'
        uses: actions/download-artifact@v6
        continue-on-error: true
        with:
          name: JUnit Test Results Phase 1
          path: test-results-phase1

      - name: Download Phase 2 test results
        if: needs.run-e2e-remaining.result == 'success' || needs.run-e2e-remaining.result == 'failure'
        uses: actions/download-artifact@v6
        continue-on-error: true
        with:
          name: JUnit Test Results Phase 2
          path: test-results-phase2

      - name: Download all tests results
        if: needs.run-e2e-all-pr.result == 'success' || needs.run-e2e-all-pr.result == 'failure' || needs.run-e2e-all-non-pr.result == 'success' || needs.run-e2e-all-non-pr.result == 'failure'
        uses: actions/download-artifact@v6
        continue-on-error: true
        with:
          name: JUnit Test Results
          path: test-results-all

      - name: Merge test results
        run: |
          mkdir -p merged-results
          cp test-results-phase1/*.xml merged-results/ 2>/dev/null || true
          cp test-results-phase2/*.xml merged-results/ 2>/dev/null || true
          cp test-results-all/*.xml merged-results/ 2>/dev/null || true
          
          # List what we have
          echo "Merged results directory contents:"
          ls -la merged-results/ || echo "No files found"

      - name: Test Report
        uses: mikepenz/action-junit-report@v5.6.2
        id: test-reporter
        if: always()
        env:
          NODE_OPTIONS: "--max_old_space_size=4096"
        with:
          commit: ${{ github.event.workflow_run.head_sha }}
          check_name: "End-to-End (E2E) Test Report"
          fail_on_failure: true
          require_tests: false
          require_passed_tests: false
          annotate_only: true
          detailed_summary: true
          include_time_in_summary: true
          group_suite: true
          updateComment: false
          report_paths: 'merged-results/*.xml'

      - name: Determine overall status
        id: overall-status
        run: |
          RELEVANT_RESULT="${{ needs.run-e2e-relevant.result }}"
          REMAINING_RESULT="${{ needs.run-e2e-remaining.result }}"
          ALL_PR_RESULT="${{ needs.run-e2e-all-pr.result }}"
          ALL_NON_PR_RESULT="${{ needs.run-e2e-all-non-pr.result }}"
          
          echo "Phase 1 (relevant): $RELEVANT_RESULT"
          echo "Phase 2 (remaining): $REMAINING_RESULT"
          echo "All tests (PR): $ALL_PR_RESULT"
          echo "All tests (Non-PR): $ALL_NON_PR_RESULT"
          
          # Determine the overall status
          if [ "$ALL_NON_PR_RESULT" = "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "description=All E2E tests passed (multi-node)" >> $GITHUB_OUTPUT
          elif [ "$ALL_NON_PR_RESULT" = "failure" ]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "description=E2E tests failed (multi-node)" >> $GITHUB_OUTPUT
          elif [ "$ALL_PR_RESULT" = "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "description=All E2E tests passed" >> $GITHUB_OUTPUT
          elif [ "$ALL_PR_RESULT" = "failure" ]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "description=E2E tests failed" >> $GITHUB_OUTPUT
          elif [ "$RELEVANT_RESULT" = "failure" ]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "description=Phase 1 (relevant tests) failed" >> $GITHUB_OUTPUT
          elif [ "$REMAINING_RESULT" = "failure" ]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "description=Phase 2 (remaining tests) failed" >> $GITHUB_OUTPUT
          elif [ "$RELEVANT_RESULT" = "success" ] && [ "$REMAINING_RESULT" = "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "description=All E2E tests passed (both phases)" >> $GITHUB_OUTPUT
          elif [ "$RELEVANT_RESULT" = "success" ] && [ "$REMAINING_RESULT" = "skipped" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "description=Phase 1 passed, Phase 2 skipped (no remaining tests)" >> $GITHUB_OUTPUT
          elif [ "$RELEVANT_RESULT" = "skipped" ] && [ "$REMAINING_RESULT" = "skipped" ] && [ "$ALL_PR_RESULT" = "skipped" ] && [ "$ALL_NON_PR_RESULT" = "skipped" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "description=No tests needed to run" >> $GITHUB_OUTPUT
          else
            echo "status=error" >> $GITHUB_OUTPUT
            echo "description=E2E tests encountered an error" >> $GITHUB_OUTPUT
          fi

      - name: Update status with results
        if: always()
        continue-on-error: true
        run: |
          STATUS="${{ steps.overall-status.outputs.status }}"
          DESCRIPTION="${{ steps.overall-status.outputs.description }}"

          # Get test results if available
          TOTAL="${{ steps.test-reporter.outputs.total || 0 }}"
          PASSED="${{ steps.test-reporter.outputs.passed || 0 }}"
          FAILED="${{ steps.test-reporter.outputs.failed || 0 }}"
          SKIPPED="${{ steps.test-reporter.outputs.skipped || 0 }}"

          if [ "$TOTAL" != "0" ]; then
            DESCRIPTION="$DESCRIPTION: $PASSED passed, $SKIPPED skipped, $FAILED failed"
          fi

          DESCRIPTION_ESCAPED=$(echo "$DESCRIPTION" | sed 's/"/\\"/g')
          JSON_PAYLOAD='{"state":"'$STATUS'","context":"${{ env.STATUS_CONTEXT }}","description":"'$DESCRIPTION_ESCAPED'","target_url":"${{ env.TARGET_URL }}"}'
          echo "JSON payload: $JSON_PAYLOAD"

          curl -X POST \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "${{ env.STATUSES_REQUEST_URL }}" \
            -d "$JSON_PAYLOAD"

      - name: Find PR number
        if: always() && github.event.workflow_run.event == 'pull_request'
        id: find-pr
        continue-on-error: true
        run: |
          BRANCH_NAME=${{ github.event.workflow_run.head_branch }}
          echo "Checking if PR exists for head ref: $BRANCH_NAME."

          PR_RESPONSE=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/pulls?head=${{ github.repository_owner }}:$BRANCH_NAME")

          PR_NUMBER=$(echo "$PR_RESPONSE" | grep -o '"number": [0-9]*,' | head -1 | sed 's/"number": //g' | sed 's/,//g' | tr -d ' \t\n\r')

          if [ -n "$PR_NUMBER" ] && [ "$PR_NUMBER" != "null" ]; then
            echo "Found PR: $PR_NUMBER from branch: $BRANCH_NAME."
            echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
          else
            echo "No PR found from branch: $BRANCH_NAME."
          fi

      - name: Add test results comment to PR
        if: always() && steps.find-pr.outputs.pr_number != ''
        uses: actions/github-script@v8
        continue-on-error: true
        with:
          script: |
            const prNumber = ${{ steps.find-pr.outputs.pr_number }};
            const testSummary = `${{ steps.test-reporter.outputs.summary || 'No test summary available' }} ${{ steps.test-reporter.outputs.detailed_summary || '' }}`;
            const status = `${{ steps.overall-status.outputs.status }}`;
            const description = `${{ steps.overall-status.outputs.description }}`;
            
            const runAllTests = `${{ needs.determine-tests.outputs.run_all_tests || 'unknown' }}`;
            const relevantTests = `${{ needs.determine-tests.outputs.relevant_tests || '' }}`;
            const remainingTests = `${{ needs.determine-tests.outputs.remaining_tests || '' }}`;
            
            let phaseInfo = '';
            if (runAllTests === 'true') {
              phaseInfo = '**Test Strategy:** Running all tests (configuration or infrastructure changes detected)\n\n';
            } else if (relevantTests || remainingTests) {
              phaseInfo = `**Test Strategy:** Two-phase execution\n`;
              phaseInfo += `- **Phase 1 (Relevant):** ${relevantTests || 'None'}\n`;
              phaseInfo += `- **Phase 2 (Remaining):** ${remainingTests || 'None'}\n\n`;
            } else {
              phaseInfo = '**Test Strategy:** Running all tests\n\n';
            }

            github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: `### End-to-End (E2E) Test Results Summary\n\n${phaseInfo}**Status:** ${description}\n\n${testSummary}`
              });
